{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1) In this task, you are required to use PySpark and the MapReduce paradigm to identify the connected components in a flight network graph. The focus should be on airports rather than cities. As you know, a connected component refers to a group of airports where every pair of airports within the group is connected either directly or indirectly.\n",
        "\n",
        "The function takes the following inputs:\n",
        "\n",
        "\n",
        "1.   Flight network\n",
        "2.   A starting date\n",
        "3.   An end date\n",
        "\n",
        "\n",
        "The function outputs:\n",
        "\n",
        "1.   The number of the connected components during that period\n",
        "2.   The size of each connectd component\n",
        "3.   The airports within the largest connected component identified"
      ],
      "metadata": {
        "id": "5wFbG-Hjx698"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first thing to do is the Data Processing. So, after loading the data from the .CSV file, I have to:\n",
        "\n",
        "*   filter flights based on a specified date range(*start_date* and *end_date*).\n",
        "*   extract edges representing direct flights between airports.\n",
        "\n",
        "After that, I have to implement the connected components algorithm using the **MapReduce** paradigm. So the things that I have to do are:\n",
        "\n",
        "\n",
        "*   Initialize each airport with its own unique ID.\n",
        "*   Iteratively propagate the smallest component ID across connected airports until convergence.\n",
        "\n",
        "This will allow me to calculate the outputs of the function, that are:\n",
        "\n",
        "\n",
        "*   The total number of the connected components.\n",
        "*   The size of each connected component.\n",
        "*   Identify the airports in the largest connected component\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lGpx46FTXeph"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function \"***preprocess_data***\" has these parameters:\n",
        "\n",
        "*   **csv_file**: Path to the flight data CSV file.\n",
        "*   **start_date**: Start of the date range (inclusive).\n",
        "*   **end_date**: End of the date range (inclusive).\n",
        "\n",
        "And returns a list of tuples representing graph edges (Origin_airport, Destination_airport).\n",
        "\n",
        "Function \"***connected_components_mapreduce***\" has this parameter:\n",
        "\n",
        "*   **flight_edges**: List of tuples representing the edges of the graph.\n",
        "\n",
        "And returns a dictionary containing the number of components, their sizes, and the largest component's airports.\n",
        "\n",
        "Function \"***map_to_min_component***\" has these parameters:\n",
        "\n",
        "*   **edge**: Tuple representing an edge (src, dest).    \n",
        "*   **components_dict**: Current component assignments for all airports.\n",
        "\n",
        "And returns a list of tuples mapping airports to the smallest component ID.\n",
        "\n",
        "Function \"***has_converged***\" has these parameters:\n",
        "\n",
        "\n",
        "*   **prev**: RDD of previous component assignments.\n",
        "*   **current**: RDD of current component assignments.\n",
        "\n",
        "And returns a boolean indicating convergence.\n",
        "\n",
        "Function \"***run_connected_components***\" has these parameters:\n",
        "\n",
        "*   **csv_file**: Path to the flight data CSV file.\n",
        "*   **start_date**: Start of the date range (inclusive).\n",
        "*   **end_date**: End of the date range (inclusive)."
      ],
      "metadata": {
        "id": "jw9Ji16tbtA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pyspark import SparkContext, SparkConf\n",
        "\n",
        "def preprocess_data(csv_file, start_date, end_date):\n",
        "\n",
        "    # Preprocesses the flight data to filter records within the specified date range and prepares edges for graph analysis\n",
        "    # Load the dataset\n",
        "    data = pd.read_csv(csv_file)\n",
        "\n",
        "    # Ensure Fly_date is in datetime format for filtering\n",
        "    data[\"Fly_date\"] = pd.to_datetime(data[\"Fly_date\"])\n",
        "\n",
        "    # Filter records within the specified date range\n",
        "    filtered_data = data[(data[\"Fly_date\"] >= start_date) & (data[\"Fly_date\"] <= end_date)]\n",
        "\n",
        "    # Select columns relevant for edges and remove duplicates\n",
        "    edges = filtered_data[[\"Origin_airport\", \"Destination_airport\"]].dropna().drop_duplicates()\n",
        "\n",
        "    return edges.values.tolist()  # Convert to list of tuples for further processing\n",
        "\n",
        "def connected_components_mapreduce(flight_edges):\n",
        "\n",
        "    # Identifies connected components in the flight network using the MapReduce paradigm\n",
        "    # Initialize Spark\n",
        "    conf = SparkConf().setAppName(\"ConnectedComponents\").setMaster(\"local\")\n",
        "    sc = SparkContext(conf=conf)\n",
        "\n",
        "    # Convert edge list to RDD\n",
        "    edges_rdd = sc.parallelize(flight_edges)\n",
        "\n",
        "    # Initialize each airport with itself as its component\n",
        "    def initialize_components(edge):\n",
        "        src, dest = edge\n",
        "        return [(src, src), (dest, dest)]  # Each airport is its own component initially\n",
        "\n",
        "    components = edges_rdd.flatMap(initialize_components).reduceByKey(lambda x, y: x)  # Reduce ensures no duplicates\n",
        "\n",
        "    # Propagate the smallest component ID iteratively\n",
        "    def map_to_min_component(edge, components_dict):\n",
        "\n",
        "        # Maps each edge to propagate the smallest component ID to both endpoints\n",
        "        src, dest = edge\n",
        "        src_component = components_dict.get(src, src)\n",
        "        dest_component = components_dict.get(dest, dest)\n",
        "        min_component = min(src_component, dest_component)\n",
        "        return [(src, min_component), (dest, min_component)]\n",
        "\n",
        "    def has_converged(prev, current):\n",
        "\n",
        "        # Checks if the component assignments have stabilized\n",
        "\n",
        "        return prev.subtractByKey(current).isEmpty()\n",
        "\n",
        "    prev_components = components  # Initialize the first iteration\n",
        "    converged = False  # Convergence flag\n",
        "\n",
        "    while not converged:\n",
        "\n",
        "        # Collect current component assignments as a dictionary for quick lookup\n",
        "        components_dict = prev_components.collectAsMap()\n",
        "\n",
        "        # Update components by mapping edges to the smallest component ID\n",
        "        updated_components = edges_rdd.flatMap(lambda edge: map_to_min_component(edge, components_dict))\n",
        "        current_components = updated_components.reduceByKey(lambda x, y: min(x, y))  # Reduce to keep smallest ID\n",
        "\n",
        "        # Check for convergence\n",
        "        converged = has_converged(prev_components, current_components)\n",
        "        prev_components = current_components\n",
        "\n",
        "    final_components = prev_components\n",
        "\n",
        "    # Calculate the size of each connected component\n",
        "    component_sizes = final_components.map(lambda x: (x[1], 1)).reduceByKey(lambda x, y: x + y)\n",
        "\n",
        "    # Find the largest component by size\n",
        "    largest_component = component_sizes.max(key=lambda x: x[1])\n",
        "    largest_component_airports = final_components.filter(lambda x: x[1] == largest_component[0]).map(lambda x: x[0]).collect()\n",
        "\n",
        "    # Return results\n",
        "    num_components = component_sizes.count()  # Total number of connected components\n",
        "    component_sizes_list = component_sizes.collect()  # List of component sizes\n",
        "\n",
        "    return {\n",
        "        \"num_components\":             num_components,\n",
        "        \"component_sizes\":            component_sizes_list,\n",
        "        \"largest_component_airports\": largest_component_airports\n",
        "    }\n",
        "\n",
        "def run_connected_components(csv_file, start_date, end_date):\n",
        "\n",
        "    # Executes the full process of identifying connected components in the flight network\n",
        "\n",
        "    # Preprocess the data to extract graph edges\n",
        "    flight_edges = preprocess_data(csv_file, start_date, end_date)\n",
        "\n",
        "    # Run the connected components algorithm\n",
        "    result = connected_components_mapreduce(flight_edges)\n",
        "\n",
        "    # Output results\n",
        "    print(\"Number of connected components:\", result[\"num_components\"])\n",
        "    print(\"Sizes of each component:\", result[\"component_sizes\"])\n",
        "    print(\"Airports in the largest component:\", result[\"largest_component_airports\"])"
      ],
      "metadata": {
        "id": "7pCdJpRpaj_m"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example of usage"
      ],
      "metadata": {
        "id": "8fllQKeabOtm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "csv_file = \"/content/drive/MyDrive/Colab Notebooks/ADM Homeworks/Homework 5/Airports2.csv\"  # Path to the dataset\n",
        "start_date = \"1990-01-01\"\n",
        "end_date = \"1990-12-31\"\n",
        "\n",
        "run_connected_components(csv_file, start_date, end_date)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "We16oGC6bQPx",
        "outputId": "5403c2bf-c0f7-4808-d5b5-295f21636392"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of connected components: 65\n",
            "Sizes of each component: [('BLI', 2), ('EUG', 2), ('ABQ', 35), ('ABE', 46), ('ABI', 10), ('EKO', 1), ('ATL', 24), ('BDL', 7), ('ELM', 1), ('AVP', 1), ('ANC', 9), ('HNL', 2), ('AMA', 1), ('ACV', 6), ('ACT', 1), ('BWI', 7), ('AGS', 7), ('CAK', 1), ('BIL', 10), ('BFL', 4), ('ALB', 6), ('ADQ', 2), ('FAR', 1), ('AZO', 4), ('ATW', 4), ('ACY', 2), ('MIA', 2), ('EYW', 1), ('CYS', 1), ('IDA', 1), ('DFW', 3), ('CID', 1), ('EAT', 1), ('BOS', 1), ('CPR', 1), ('DAY', 1), ('CMH', 1), ('BFI', 2), ('FAT', 2), ('CEC', 1), ('GPT', 1), ('AIY', 1), ('FOE', 1), ('FCA', 2), ('ALW', 3), ('CLM', 1), ('BHM', 1), ('CVG', 1), ('BIF', 1), ('EFD', 1), ('FLG', 1), ('AVL', 1), ('CHO', 1), ('GEG', 2), ('GCC', 1), ('FFO', 1), ('FMN', 1), ('EWN', 2), ('BGM', 1), ('FAI', 1), ('SPI', 1), ('BRO', 1), ('ADM', 1), ('BFF', 1), ('NGP', 1)]\n",
            "Airports in the largest component: ['SEA', 'PIT', 'CVG', 'BOS', 'ATL', 'ORD', 'MDW', 'PHL', 'DTW', 'MSP', 'CLT', 'EWR', 'BWI', 'LGA', 'MDT', 'ROC', 'IND', 'GRR', 'DAY', 'CLE', 'BNA', 'DCA', 'IAD', 'JFK', 'MIA', 'MSY', 'BUF', 'SYR', 'RIC', 'AVL', 'BHM', 'MKE', 'TPA', 'MEM', 'RDU', 'CAE', 'JAX', 'PBI', 'ALB', 'SBN', 'AVP', 'GSP', 'PVD', 'MSN', 'ACY', 'ABE']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Compare the execution time and the results of your implementation with those of the GraphFrames package for identifying connected components. If there is any difference in the results, provide an explanation for why that might occur.\n"
      ],
      "metadata": {
        "id": "fLlUevqyiFG2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First of all, I install the GraphFrames package"
      ],
      "metadata": {
        "id": "fMbKykcbiGzy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install graphframes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gx52h5C0iW92",
        "outputId": "880de9c5-e95f-4be2-c146-e787629b8c1c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: graphframes in /usr/local/lib/python3.10/dist-packages (0.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from graphframes) (1.26.4)\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.10/dist-packages (from graphframes) (1.3.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function \"***run_graphframes_connected_components***\" has this parameter:\n",
        "\n",
        "*   **flight_edges**: List of tuples representing the edges of the graph.\n",
        "\n",
        "And returns a dictionary containing the results from GraphFrames."
      ],
      "metadata": {
        "id": "h6hckcfxiifF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "def run_graphframes_connected_components(flight_edges):\n",
        "\n",
        "    # Identifies connected components using the GraphFrames package.\n",
        "    # Check if a SparkSession already exists\n",
        "    spark = SparkSession.builder \\\n",
        "        .appName(\"GraphFramesConnectedComponents\") \\\n",
        "        .config(\"spark.jars.packages\", \"graphframes:graphframes:0.8.2-spark3.0-s_2.12\") \\\n",
        "        .getOrCreate()\n",
        "\n",
        "    # Create vertices and edges DataFrame\n",
        "    airports = list(set([airport for edge in flight_edges for airport in edge]))\n",
        "    vertices = spark.createDataFrame([(a,) for a in airports], [\"id\"])\n",
        "    edges = spark.createDataFrame(flight_edges, [\"src\", \"dst\"])\n",
        "\n",
        "    # Create GraphFrame\n",
        "    from graphframes import GraphFrame\n",
        "    g = GraphFrame(vertices, edges)\n",
        "\n",
        "    # Run connected components\n",
        "    result = g.connectedComponents()\n",
        "\n",
        "    # Collect results\n",
        "    component_sizes = result.groupBy(\"component\").count().collect()\n",
        "    largest_component = max(component_sizes, key=lambda x: x[\"count\"])\n",
        "    largest_component_airports = result.filter(col(\"component\") == largest_component[\"component\"]).select(\"id\").collect()\n",
        "\n",
        "    return {\n",
        "        \"num_components\": len(component_sizes),\n",
        "        \"component_sizes\": [(row[\"component\"], row[\"count\"]) for row in component_sizes],\n",
        "        \"largest_component_airports\": [row[\"id\"] for row in largest_component_airports]\n",
        "    }"
      ],
      "metadata": {
        "id": "AzV8FU2jjcbC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare Execution Times"
      ],
      "metadata": {
        "id": "41bWEqyBjvcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Close existing SparkSession to avoid multiple contexts\n",
        "from pyspark import SparkContext\n",
        "if SparkContext._active_spark_context:\n",
        "    SparkContext._active_spark_context.stop()\n",
        "\n",
        "# Preprocess the data to get the graph edges\n",
        "flight_edges = preprocess_data(csv_file, start_date, end_date)\n",
        "\n",
        "# Measure execution time of the custom MapReduce implementation\n",
        "start_time = time.time()\n",
        "custom_result = connected_components_mapreduce(flight_edges)\n",
        "custom_time = time.time() - start_time\n",
        "\n",
        "# Measure execution time of GraphFrames\n",
        "start_time = time.time()\n",
        "graphframes_result = run_graphframes_connected_components(flight_edges)\n",
        "graphframes_time = time.time() - start_time\n",
        "\n",
        "# Print results\n",
        "print(\"Custom Implementation:\")\n",
        "print(f\"Execution Time: {custom_time:.2f} seconds\")\n",
        "print(f\"Number of Components: {custom_result['num_components']}\")\n",
        "print(f\"Sizes of Components: {custom_result['component_sizes']}\")\n",
        "print(f\"Largest Component Airports: {custom_result['largest_component_airports']}\")\n",
        "\n",
        "print(\"\\nGraphFrames Implementation:\")\n",
        "print(f\"Execution Time: {graphframes_time:.2f} seconds\")\n",
        "print(f\"Number of Components: {graphframes_result['num_components']}\")\n",
        "print(f\"Sizes of Components: {graphframes_result['component_sizes']}\")\n",
        "print(f\"Largest Component Airports: {graphframes_result['largest_component_airports']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "dypYKHhZjupK",
        "outputId": "3a0208c8-0e9d-45f2-dc03-4501cd78c5d5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py:168: UserWarning: DataFrame.sql_ctx is an internal property, and will be removed in future releases. Use DataFrame.sparkSession instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "An error occurred while calling o347.loadClass.\n: java.lang.ClassNotFoundException: org.graphframes.GraphFramePythonAPI\n\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:476)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:594)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:527)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-a756a3ab9e63>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Measure execution time of GraphFrames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mgraphframes_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_graphframes_connected_components\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflight_edges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mgraphframes_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-9abb051fe563>\u001b[0m in \u001b[0;36mrun_graphframes_connected_components\u001b[0;34m(flight_edges)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Create GraphFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mgraphframes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGraphFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGraphFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Run connected components\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/graphframes/graphframe.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, v, e)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sqlContext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sqlContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm_gf_api\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_java_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm_gf_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/graphframes/graphframe.py\u001b[0m in \u001b[0;36m_java_api\u001b[0;34m(jsc)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_java_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjsc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mjavaClassName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"org.graphframes.GraphFramePythonAPI\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mjsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mThread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrentThread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetContextClassLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjavaClassName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0;34m.\u001b[0m\u001b[0mnewInstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o347.loadClass.\n: java.lang.ClassNotFoundException: org.graphframes.GraphFramePythonAPI\n\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:476)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:594)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:527)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
          ]
        }
      ]
    }
  ]
}